# Paper list

Here is a preliminary list of papers that we will choose from to discuss in this class.
If you are interested in reading a paper that is not on this list, don't worry, you'll get the opportunity to suggest it!

| **Title** | **Approach** | **Domain** |
|---|---|---|
| [Semi-Supervised Learning with Deep Generative Models](https://arxiv.org/abs/1406.5298) | Semi-Supervised Learning | CV |
| [Learning and Transferring Mid-Level Image Representations using Convolutional Neural Networks](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf) | Transfer Learning | CV |
| [How transferable are features in deep neural networks?](https://arxiv.org/abs/1411.1792) | Transfer Learning | CV |
| [Skip-Thought Vectors](https://arxiv.org/abs/1506.06726) | Transfer/Representation Learning | NLP |
| [Semi-Supervised Sequence Learning](https://arxiv.org/abs/1511.01432) | Transfer Learning | NLP |
| [Learning Distributed Representations of Sentences from Unlabelled Data](https://arxiv.org/abs/1602.03483) | Transfer Learning | NLP |
| [Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725) | Semi-Supervised Learning | NLP |
| [Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning](https://arxiv.org/abs/1606.04586) | Semi-Supervised Learning | CV |
| [What makes ImageNet good for transfer learning?](https://arxiv.org/abs/1608.08614) | Transfer Learning | CV |
| [Temporal Ensembling for Semi-Supervised Learning](https://arxiv.org/abs/1610.02242) | Semi-Supervised Learning | CV |
| [Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning](https://arxiv.org/abs/1704.03976) | Semi-Supervised Learning | CV |
| [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](https://arxiv.org/abs/1705.02364) | Transfer/Representation Learning | NLP |
| [Good Semi-supervised Learning that Requires a Bad GAN](https://arxiv.org/abs/1705.09783) | Semi-Supervised Learning | CV |
| [Snorkel: Rapid Training Data Creation with Weak Supervision](https://arxiv.org/abs/1711.10160) | Weak/Active Learning | Many |
| [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146) | Transfer Learning | NLP |
| [Deep Contextualized Word Representations](https://arxiv.org/abs/1802.05365) | Transfer Learning | NLP |
| [An efficient framework for learning sentence representations](https://arxiv.org/abs/1803.02893) | Transfer/Representation Learning | NLP |
| [Universal Sentence Encoder](https://arxiv.org/abs/1803.11175) | Transfer/Representation Learning | NLP |
| [Exploring the Limits of Weakly Supervised Pretraining](https://arxiv.org/abs/1805.00932) | Transfer Learning | CV |
| [Do Better ImageNet Models Transfer Better?](https://arxiv.org/abs/1805.08974) | Transfer Learning | CV |
| [Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) | Transfer Learning | NLP |
| [Understanding Back-Translation at Scale](https://arxiv.org/abs/1808.09381) | Semi-Supervised Learning | NLP |
| [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) | Transfer Learning | NLP |
| [Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks](https://arxiv.org/abs/1811.01088) | Transfer Learning | NLP |
| [Rethinking ImageNet Pre-Training](https://arxiv.org/abs/1811.08883) | Transfer Learning | CV |
| [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291) | Transfer Learning | NLP |
| [Multi-Task Deep Neural Networks for Natural Language Understanding](https://arxiv.org/abs/1901.11504) | Transfer Learning | NLP |
| [Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751) | Transfer Learning | NLP |
| [Task2Vec: Task Embedding for Meta-Learning](https://arxiv.org/abs/1902.03545) | Transfer Learning | CV |
| [To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks](https://arxiv.org/abs/1903.05987) | Transfer Learning | NLP |
| [Unsupervised Data Augmentation for Consistency Training](https://arxiv.org/abs/1904.12848) | Semi-Supervised Learning | CV + NLP |
| [Billion-scale semi-supervised learning for image classification](https://arxiv.org/abs/1905.00546) | Semi-Supervised Learning | CV |
| [MixMatch: A Holistic Approach to Semi-Supervised Learning](https://arxiv.org/abs/1905.02249) | Semi-Supervised Learning | CV |
| [MASS: Masked Sequence to Sequence Pre-training for Language Generation](https://arxiv.org/abs/1905.02450) | Transfer Learning | NLP |
| [Unified Language Model Pre-training for Natural Language Understanding and Generation](https://arxiv.org/abs/1905.03197) | Transfer Learning | NLP |
| [S4L: Self-Supervised Semi-Supervised Learning](https://arxiv.org/abs/1905.03670) | Semi-Supervised Learning | CV |
| [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/abs/1905.05583) | Transfer Learning | NLP |
| [Data-Efficient Image Recognition with Contrastive Predictive Coding](https://arxiv.org/abs/1905.09272) | Transfer/Representation Learning | CV |
| [Synthetic QA Corpora Generation with Roundtrip Consistency](https://arxiv.org/abs/1906.05416) | Semi-Supervised Learning | NLP |
| [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) | Transfer Learning | NLP |
| [Large Scale Adversarial Representation Learning](https://arxiv.org/abs/1907.02544) | Transfer/Representation Learning | CV |
| [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) | Transfer Learning | NLP |
| [Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning](https://arxiv.org/abs/1908.02983) | Semi-Supervised Learning | CV |
| [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.1194) | Transfer Learning | NLP |
| [Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/abs/1911.04252) | Semi-Supervised Learning | CV |
| [Fidelity-Weighted Learning](https://arxiv.org/abs/1711.02799) | Semi-Supervised Learning | NLP |
| [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722) | Transfer/Representation Learning | CV |
| [Big Transfer (BiT): General Visual Representation Learning](https://arxiv.org/abs/1912.11370) | Transfer Learning | CV |
| [Semi-Supervised Learning with Normalizing Flows](https://arxiv.org/abs/1912.13025) | Semi-Supervised Learning | Many |
| [FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence](https://arxiv.org/abs/2001.07685) | Semi-Supervised Learning | CV |
| [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) | Transfer/Representation Learning | CV |
| [Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping](https://arxiv.org/abs/2002.06305) | Transfer Learning | NLP |
| [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://arxiv.org/abs/2003.10555) | Transfer Learning | NLP |
| [Rethinking Pre-training and Self-training](https://arxiv.org/abs/2006.06882) | Transfer and Semi-Supervised Learning | CV |
| [Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning](https://arxiv.org/abs/2006.07733) | Transfer/Representation Learning | CV |
| [Unsupervised Learning of Visual Features by Contrasting Cluster Assignments](https://arxiv.org/abs/2006.09882) | Transfer/Representation Learning | CV |
| [Big Self-Supervised Models are Strong Semi-Supervised Learners](https://arxiv.org/abs/2006.10029) | Semi-Supervised Learning | CV |
